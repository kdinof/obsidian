### Когда переходить к более строгому процессу улучшения промптов

При разработке решения на основе генеративного AI всегда имеет смысл начинать с простого промпта, проверки его на маленькой выборке данных и быстрых итераций по улучшению. Такой подход позволяет быстро двигаться вперед и улучшать качество.

Если через несколько итераций у вас получилось добиться приемлемого качества на нескольких примерах, то имеет смысл переходить к более строгому процессу, где вы будете тестировать промпт на более крупной выборке данных. 

Рекомендуемый объем выборки — хотя бы несколько десятков примеров. Чем больше будет примеров и чем разнообразнее они будут, тем точнее будет результат оценки и тем быстрее вы будете добиваться прогресса в улучшении качества. 

Иными словами, чем больше будет отражено в данных примеров реальных условий применения сервиса, тем больше ошибок мы сможем отловить и на их основе улучшить промпт.

### Оценка качества промптов: обучающий и тестовый датасеты

Типовой подход для оценки качества промптов не отличается от оценки качества любой другой ML-модели.

Мы будем использовать обучающий и тестовый датасеты:

- На обучающем датасете мы будем подбирать промпты, анализировать ошибки и стараться добиться оптимального качества. 
- На тестовом датасете мы будем проводить финальную оценку качества промпта. Тестовый датасет имитирует реальное применение модели в будущем, поэтому он должен быть: 
    - Независимым от обучающего датасета.
    - Репрезентативным, то есть имитировать данные, которые будут подаваться модели в продакшене.

Если оценка качества на тестовом датасете покажет неудовлетворительное качество, то нужно будет вернуться на этап оптимизации промпта. Но перед этим важно: 

- Добавить к обучающему датасету данные из тестового датасета и провести анализ ошибок. Это позволит решить найденные проблемы.
- Сделать новый тестовый датасет для финальной оценки качества. Прошлый датасет больше нельзя будет использовать, так как мы теперь уже полагаемся на него для обучения и улучшения промпта.
![[Pasted image 20240629153353.png]]

Для всех ML-задач, в том числе и генеративных, выбор метрик качества модели должен исходить из четкого понимания того, что такое хороший и плохой ответ модели.

Почему мы считаем его низким? 
Для оценки качества в такой задаче удобно использовать «сравнение с человеком», так как мы пытаемся автоматизировать ручной труд. В нашей задаче человек без специальной подготовки покажет результат как минимум на уровне 0.95 для метрики «доля релевантных тем».



### Выбор LLM для конкретной задачи

На рынке доступно множество больших языковых моделей. Их перечень постоянно обновляется (можно воспользоваться, например, ресурсом [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)). Даже в линейке моделей GPT от OpenAI представлено [много вариантов](https://platform.openai.com/docs/models) с различным количеством параметров, производительностью и стоимостью использования. 

Выбор модели будет зависеть от многих параметров решаемой задачи. Общие рекомендации по выбору моделей — [в лекции Andrew NG “Advanced technologies beyond prompting”, курс “Generative AI for Everyone](https://www.deeplearning.ai/courses/generative-ai-for-everyone/)”.




---


https://www.promptingguide.ai/techniques/ape #prompt #promptngineering 